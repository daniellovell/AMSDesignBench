bench_version: 0.1.0
rubric_version: 0.1.0
random_seed: 1234
eval:
  max_tokens: 800
  temperature: 0.2
  top_p: 0.95
  models: ["openai:gpt-4o-mini", "openai:gpt-5-nano", "anthropic:claude-3-5-haiku-latest"]
limits:
  max_items: null
  timeout_s: 60
paths:
  data_root: data
  prompts_root: prompts
  outputs_root: outputs

# Design verification settings
design_verification:
  enabled: true
  pdk:
    name: skywater130
    path: pdk/skywater130
  simulation:
    engine: ngspice
    timeout_s: 120
    use_gmid_tables: true
  eval:
    # Design-specific LLM settings
    max_tokens: 2000  # Larger for netlist generation
    temperature: 0.3
    include_gmid_tables: true
